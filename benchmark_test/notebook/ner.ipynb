{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12f227bb",
   "metadata": {},
   "source": [
    " * @ Author: Yohei Ohto\n",
    " * @ Create Time: 2025-11-28 20:10:30\n",
    " * @ Modified time: 2025-11-28 20:15:46\n",
    " * @ Description: 既存MLMへのNER実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21858a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/test_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import torch\n",
    "import wandb\n",
    "from datasets import load_dataset\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (AutoModel, AutoModelForTokenClassification,\n",
    "                          AutoTokenizer, DataCollatorWithPadding, Trainer, DataCollatorForTokenClassification,\n",
    "                          TrainingArguments)\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d7d1b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\",\n",
    "    \"dmis-lab/biobert-v1.1\",\n",
    "    \"google-bert/bert-base-cased\",\n",
    "    \"answerdotai/ModernBERT-base\",\n",
    "    \"Simonlee711/Clinical_ModernBERT\",\n",
    "    \"thomas-sounack/BioClinical-ModernBERT-base\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd80014",
   "metadata": {},
   "source": [
    "# NCBI Desease Named Entity Recognition Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1961ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"ncbi/ncbi_disease\")\n",
    "\n",
    "label_names = [\n",
    "    \"O\", \"B-DISEASE\", \"I-DISEASE\"\n",
    "]\n",
    "\n",
    "id2label = {i: name for i, name in enumerate(label_names)}\n",
    "label2id = {name: i for i, name in enumerate(label_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38bb98e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p: tuple):\n",
    "    \"\"\"\n",
    "    NERの評価指標を計算する関数\n",
    "    Args:\n",
    "        p: モデルの予測結果とラベルのタプル (predictions, labels)\n",
    "        label_names (list): ラベル名のリスト\n",
    "    Returns:\n",
    "        dict: precision, recall, f1, accuracyを含む辞書\n",
    "    How to use:\n",
    "        from transformers import Trainer\n",
    "\n",
    "        trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "        )\n",
    "        \n",
    "    \"\"\"\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_names[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    seqeval = evaluate.load(\"seqeval\")\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    \n",
    "    return {\n",
    "        \"precision\": float(results[\"overall_precision\"]),\n",
    "        \"recall\": float(results[\"overall_recall\"]),\n",
    "        \"f1\": float(results[\"overall_f1\"]),\n",
    "        \"accuracy\": float(results[\"overall_accuracy\"]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e992921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model: microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext  Training ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▅▆▆▆█▇███</td></tr><tr><td>eval/f1</td><td>▁▆▅▆▇▇█▇█▇▇</td></tr><tr><td>eval/loss</td><td>▄▁▂▄▆▆▇█▇██</td></tr><tr><td>eval/precision</td><td>▁▅▅▅█▇▇▇█▇▇</td></tr><tr><td>eval/recall</td><td>▁▇▅█▄▇█▇█▇▇</td></tr><tr><td>eval/runtime</td><td>▂▁▄▂▂▁▂▃█▅▂</td></tr><tr><td>eval/samples_per_second</td><td>▇█▅▇▇█▇▆▁▄▇</td></tr><tr><td>eval/steps_per_second</td><td>▇█▅▇▇█▇▆▁▄▇</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.98719</td></tr><tr><td>eval/f1</td><td>0.86646</td></tr><tr><td>eval/loss</td><td>0.08657</td></tr><tr><td>eval/precision</td><td>0.8552</td></tr><tr><td>eval/recall</td><td>0.87802</td></tr><tr><td>eval/runtime</td><td>1.9531</td></tr><tr><td>eval/samples_per_second</td><td>473.097</td></tr><tr><td>eval/steps_per_second</td><td>29.697</td></tr><tr><td>test/accuracy</td><td>0.98719</td></tr><tr><td>test/f1</td><td>0.86646</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext</strong> at: <a href='https://wandb.ai/250502_ohto_research/NCBI-disease/runs/fgaxqmqr' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease/runs/fgaxqmqr</a><br> View project at: <a href='https://wandb.ai/250502_ohto_research/NCBI-disease' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease</a><br>Synced 2 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251128_213112-fgaxqmqr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/1-project/1-nlp/github/nlp-util/benchmark_test/notebook/wandb/run-20251129_130406-pim9oqkp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/250502_ohto_research/NCBI-disease/runs/pim9oqkp' target=\"_blank\">BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext</a></strong> to <a href='https://wandb.ai/250502_ohto_research/NCBI-disease' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/250502_ohto_research/NCBI-disease' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/250502_ohto_research/NCBI-disease/runs/pim9oqkp' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease/runs/pim9oqkp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_843539/3916018160.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3400' max='3400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3400/3400 03:18, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.058861</td>\n",
       "      <td>0.799257</td>\n",
       "      <td>0.819568</td>\n",
       "      <td>0.809285</td>\n",
       "      <td>0.983270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>0.049048</td>\n",
       "      <td>0.831902</td>\n",
       "      <td>0.861499</td>\n",
       "      <td>0.846442</td>\n",
       "      <td>0.986733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.051331</td>\n",
       "      <td>0.847666</td>\n",
       "      <td>0.876747</td>\n",
       "      <td>0.861961</td>\n",
       "      <td>0.987025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.063080</td>\n",
       "      <td>0.841596</td>\n",
       "      <td>0.884371</td>\n",
       "      <td>0.862454</td>\n",
       "      <td>0.986691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.079091</td>\n",
       "      <td>0.855879</td>\n",
       "      <td>0.860229</td>\n",
       "      <td>0.858048</td>\n",
       "      <td>0.986649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.075670</td>\n",
       "      <td>0.864492</td>\n",
       "      <td>0.875476</td>\n",
       "      <td>0.869949</td>\n",
       "      <td>0.987692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.076995</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.889454</td>\n",
       "      <td>0.875547</td>\n",
       "      <td>0.988318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.087122</td>\n",
       "      <td>0.854637</td>\n",
       "      <td>0.866582</td>\n",
       "      <td>0.860568</td>\n",
       "      <td>0.986900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.090444</td>\n",
       "      <td>0.852399</td>\n",
       "      <td>0.880559</td>\n",
       "      <td>0.866250</td>\n",
       "      <td>0.987192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.091009</td>\n",
       "      <td>0.855721</td>\n",
       "      <td>0.874206</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.987192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model: dmis-lab/biobert-v1.1  Training ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 5433/5433 [00:00<00:00, 10511.72 examples/s]\n",
      "Map: 100%|██████████| 924/924 [00:00<00:00, 9883.75 examples/s]\n",
      "Map: 100%|██████████| 941/941 [00:00<00:00, 10245.36 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▆▆▆▇█▆▆▆▆</td></tr><tr><td>eval/f1</td><td>▁▅▇▇▆▇█▆▇▇▇</td></tr><tr><td>eval/loss</td><td>▃▁▁▃▆▅▆▇███</td></tr><tr><td>eval/precision</td><td>▁▅▆▆▇██▇▇▇▇</td></tr><tr><td>eval/recall</td><td>▁▅▇▇▅▇█▆▇▆▆</td></tr><tr><td>eval/runtime</td><td>▁▂▁▂▇▂▃▁█▅▃</td></tr><tr><td>eval/samples_per_second</td><td>█▇█▇▁▇▆█▁▄▆</td></tr><tr><td>eval/steps_per_second</td><td>█▇█▇▁▇▆█▁▄▆</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.98719</td></tr><tr><td>eval/f1</td><td>0.86486</td></tr><tr><td>eval/loss</td><td>0.09101</td></tr><tr><td>eval/precision</td><td>0.85572</td></tr><tr><td>eval/recall</td><td>0.87421</td></tr><tr><td>eval/runtime</td><td>2.0083</td></tr><tr><td>eval/samples_per_second</td><td>460.083</td></tr><tr><td>eval/steps_per_second</td><td>28.88</td></tr><tr><td>test/accuracy</td><td>0.98719</td></tr><tr><td>test/f1</td><td>0.86486</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext</strong> at: <a href='https://wandb.ai/250502_ohto_research/NCBI-disease/runs/pim9oqkp' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease/runs/pim9oqkp</a><br> View project at: <a href='https://wandb.ai/250502_ohto_research/NCBI-disease' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251129_130406-pim9oqkp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/1-project/1-nlp/github/nlp-util/benchmark_test/notebook/wandb/run-20251129_130740-fdvf45yd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/250502_ohto_research/NCBI-disease/runs/fdvf45yd' target=\"_blank\">biobert-v1.1</a></strong> to <a href='https://wandb.ai/250502_ohto_research/NCBI-disease' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/250502_ohto_research/NCBI-disease' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/250502_ohto_research/NCBI-disease/runs/fdvf45yd' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease/runs/fdvf45yd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_843539/3916018160.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3400' max='3400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3400/3400 03:59, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.045502</td>\n",
       "      <td>0.797136</td>\n",
       "      <td>0.848793</td>\n",
       "      <td>0.822154</td>\n",
       "      <td>0.985648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.066200</td>\n",
       "      <td>0.045123</td>\n",
       "      <td>0.812425</td>\n",
       "      <td>0.864041</td>\n",
       "      <td>0.837438</td>\n",
       "      <td>0.986524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.050316</td>\n",
       "      <td>0.801876</td>\n",
       "      <td>0.869123</td>\n",
       "      <td>0.834146</td>\n",
       "      <td>0.985565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>0.057627</td>\n",
       "      <td>0.829559</td>\n",
       "      <td>0.884371</td>\n",
       "      <td>0.856089</td>\n",
       "      <td>0.986608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.072629</td>\n",
       "      <td>0.819512</td>\n",
       "      <td>0.853875</td>\n",
       "      <td>0.836341</td>\n",
       "      <td>0.986524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.083978</td>\n",
       "      <td>0.822830</td>\n",
       "      <td>0.879288</td>\n",
       "      <td>0.850123</td>\n",
       "      <td>0.986649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.081287</td>\n",
       "      <td>0.823250</td>\n",
       "      <td>0.881830</td>\n",
       "      <td>0.851534</td>\n",
       "      <td>0.987275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.085997</td>\n",
       "      <td>0.830732</td>\n",
       "      <td>0.879288</td>\n",
       "      <td>0.854321</td>\n",
       "      <td>0.987192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.088947</td>\n",
       "      <td>0.832134</td>\n",
       "      <td>0.881830</td>\n",
       "      <td>0.856262</td>\n",
       "      <td>0.987025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.091457</td>\n",
       "      <td>0.835966</td>\n",
       "      <td>0.874206</td>\n",
       "      <td>0.854658</td>\n",
       "      <td>0.987317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model: google-bert/bert-base-cased  Training ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 5433/5433 [00:00<00:00, 8584.53 examples/s]\n",
      "Map: 100%|██████████| 924/924 [00:00<00:00, 10162.04 examples/s]\n",
      "Map: 100%|██████████| 941/941 [00:00<00:00, 9395.76 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅▁▅▅▅█▇▇██</td></tr><tr><td>eval/f1</td><td>▁▄▃█▄▇▇████</td></tr><tr><td>eval/loss</td><td>▁▁▂▃▅▇▆▇███</td></tr><tr><td>eval/precision</td><td>▁▄▂▇▅▆▆▇▇██</td></tr><tr><td>eval/recall</td><td>▁▄▅█▂▇▇▇▇▆▆</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▄█▁▁▁▁▁</td></tr><tr><td>eval/samples_per_second</td><td>███▇▄▁█▇███</td></tr><tr><td>eval/steps_per_second</td><td>███▇▄▁█▇███</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.98732</td></tr><tr><td>eval/f1</td><td>0.85466</td></tr><tr><td>eval/loss</td><td>0.09146</td></tr><tr><td>eval/precision</td><td>0.83597</td></tr><tr><td>eval/recall</td><td>0.87421</td></tr><tr><td>eval/runtime</td><td>2.1731</td></tr><tr><td>eval/samples_per_second</td><td>425.192</td></tr><tr><td>eval/steps_per_second</td><td>26.69</td></tr><tr><td>test/accuracy</td><td>0.98732</td></tr><tr><td>test/f1</td><td>0.85466</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">biobert-v1.1</strong> at: <a href='https://wandb.ai/250502_ohto_research/NCBI-disease/runs/fdvf45yd' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease/runs/fdvf45yd</a><br> View project at: <a href='https://wandb.ai/250502_ohto_research/NCBI-disease' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251129_130740-fdvf45yd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/1-project/1-nlp/github/nlp-util/benchmark_test/notebook/wandb/run-20251129_131157-x6jw5j9s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/250502_ohto_research/NCBI-disease/runs/x6jw5j9s' target=\"_blank\">bert-base-cased</a></strong> to <a href='https://wandb.ai/250502_ohto_research/NCBI-disease' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/250502_ohto_research/NCBI-disease' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/250502_ohto_research/NCBI-disease/runs/x6jw5j9s' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease/runs/x6jw5j9s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_843539/3916018160.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3400' max='3400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3400/3400 03:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.054626</td>\n",
       "      <td>0.765550</td>\n",
       "      <td>0.813215</td>\n",
       "      <td>0.788663</td>\n",
       "      <td>0.983312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.049490</td>\n",
       "      <td>0.764172</td>\n",
       "      <td>0.856417</td>\n",
       "      <td>0.807669</td>\n",
       "      <td>0.984647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.054863</td>\n",
       "      <td>0.788980</td>\n",
       "      <td>0.855146</td>\n",
       "      <td>0.820732</td>\n",
       "      <td>0.985398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.062253</td>\n",
       "      <td>0.806338</td>\n",
       "      <td>0.872935</td>\n",
       "      <td>0.838316</td>\n",
       "      <td>0.986649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.075521</td>\n",
       "      <td>0.822816</td>\n",
       "      <td>0.861499</td>\n",
       "      <td>0.841713</td>\n",
       "      <td>0.986483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.085204</td>\n",
       "      <td>0.814727</td>\n",
       "      <td>0.871665</td>\n",
       "      <td>0.842234</td>\n",
       "      <td>0.986733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.096046</td>\n",
       "      <td>0.794811</td>\n",
       "      <td>0.856417</td>\n",
       "      <td>0.824465</td>\n",
       "      <td>0.984689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.096441</td>\n",
       "      <td>0.812201</td>\n",
       "      <td>0.862770</td>\n",
       "      <td>0.836722</td>\n",
       "      <td>0.985898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.098305</td>\n",
       "      <td>0.816766</td>\n",
       "      <td>0.866582</td>\n",
       "      <td>0.840937</td>\n",
       "      <td>0.985940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.098568</td>\n",
       "      <td>0.824096</td>\n",
       "      <td>0.869123</td>\n",
       "      <td>0.846011</td>\n",
       "      <td>0.986065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model: answerdotai/ModernBERT-base  Training ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 5433/5433 [00:00<00:00, 10715.36 examples/s]\n",
      "Map: 100%|██████████| 924/924 [00:00<00:00, 11199.23 examples/s]\n",
      "Map: 100%|██████████| 941/941 [00:00<00:00, 10471.21 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▄▅█▇█▄▆▆▇▇</td></tr><tr><td>eval/f1</td><td>▁▃▅▇▇█▅▇▇██</td></tr><tr><td>eval/loss</td><td>▂▁▂▃▅▆█████</td></tr><tr><td>eval/precision</td><td>▁▁▄▆█▇▅▇▇██</td></tr><tr><td>eval/recall</td><td>▁▆▆█▇█▆▇▇██</td></tr><tr><td>eval/runtime</td><td>▆▃▇▂▃▄▄█▁▅▃</td></tr><tr><td>eval/samples_per_second</td><td>▂▅▂▇▆▅▅▁█▄▆</td></tr><tr><td>eval/steps_per_second</td><td>▂▅▂▇▆▅▅▁█▄▆</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.98607</td></tr><tr><td>eval/f1</td><td>0.84601</td></tr><tr><td>eval/loss</td><td>0.09857</td></tr><tr><td>eval/precision</td><td>0.8241</td></tr><tr><td>eval/recall</td><td>0.86912</td></tr><tr><td>eval/runtime</td><td>2.1379</td></tr><tr><td>eval/samples_per_second</td><td>432.201</td></tr><tr><td>eval/steps_per_second</td><td>27.129</td></tr><tr><td>test/accuracy</td><td>0.98607</td></tr><tr><td>test/f1</td><td>0.84601</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bert-base-cased</strong> at: <a href='https://wandb.ai/250502_ohto_research/NCBI-disease/runs/x6jw5j9s' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease/runs/x6jw5j9s</a><br> View project at: <a href='https://wandb.ai/250502_ohto_research/NCBI-disease' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251129_131157-x6jw5j9s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/1-project/1-nlp/github/nlp-util/benchmark_test/notebook/wandb/run-20251129_131600-luruvex3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/250502_ohto_research/NCBI-disease/runs/luruvex3' target=\"_blank\">ModernBERT-base</a></strong> to <a href='https://wandb.ai/250502_ohto_research/NCBI-disease' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/250502_ohto_research/NCBI-disease' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/250502_ohto_research/NCBI-disease/runs/luruvex3' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease/runs/luruvex3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_843539/3916018160.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n",
      "/home/ubuntu/test_env/lib/python3.12/site-packages/torch/backends/cuda/__init__.py:131: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  return torch._C._get_cublas_allow_tf32()\n",
      "/home/ubuntu/test_env/lib/python3.12/site-packages/torch/_inductor/compile_fx.py:312: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3400' max='3400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3400/3400 05:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.062356</td>\n",
       "      <td>0.724014</td>\n",
       "      <td>0.770013</td>\n",
       "      <td>0.746305</td>\n",
       "      <td>0.979181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.093800</td>\n",
       "      <td>0.053766</td>\n",
       "      <td>0.788698</td>\n",
       "      <td>0.815756</td>\n",
       "      <td>0.801999</td>\n",
       "      <td>0.983061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.068638</td>\n",
       "      <td>0.810667</td>\n",
       "      <td>0.772554</td>\n",
       "      <td>0.791152</td>\n",
       "      <td>0.983270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>0.071727</td>\n",
       "      <td>0.811180</td>\n",
       "      <td>0.829733</td>\n",
       "      <td>0.820352</td>\n",
       "      <td>0.984230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.091831</td>\n",
       "      <td>0.794083</td>\n",
       "      <td>0.852605</td>\n",
       "      <td>0.822304</td>\n",
       "      <td>0.984188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.094910</td>\n",
       "      <td>0.802663</td>\n",
       "      <td>0.842440</td>\n",
       "      <td>0.822071</td>\n",
       "      <td>0.984563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.103430</td>\n",
       "      <td>0.802211</td>\n",
       "      <td>0.829733</td>\n",
       "      <td>0.815740</td>\n",
       "      <td>0.984271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.107427</td>\n",
       "      <td>0.811648</td>\n",
       "      <td>0.832274</td>\n",
       "      <td>0.821832</td>\n",
       "      <td>0.984480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.109672</td>\n",
       "      <td>0.813200</td>\n",
       "      <td>0.829733</td>\n",
       "      <td>0.821384</td>\n",
       "      <td>0.984522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.110336</td>\n",
       "      <td>0.812189</td>\n",
       "      <td>0.829733</td>\n",
       "      <td>0.820867</td>\n",
       "      <td>0.984480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model: Simonlee711/Clinical_ModernBERT  Training ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at Simonlee711/Clinical_ModernBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 5433/5433 [00:00<00:00, 9403.64 examples/s]\n",
      "Map: 100%|██████████| 924/924 [00:00<00:00, 9594.36 examples/s]\n",
      "Map: 100%|██████████| 941/941 [00:00<00:00, 6317.89 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▆████████</td></tr><tr><td>eval/f1</td><td>▁▆▅███▇████</td></tr><tr><td>eval/loss</td><td>▂▁▃▃▆▆▇████</td></tr><tr><td>eval/precision</td><td>▁▆██▆▇▇████</td></tr><tr><td>eval/recall</td><td>▁▅▁▆█▇▆▆▆▆▆</td></tr><tr><td>eval/runtime</td><td>█▂▁▁▂▁▁▁▁▁▂</td></tr><tr><td>eval/samples_per_second</td><td>▁▇▇█▇█▇▇▇▇▇</td></tr><tr><td>eval/steps_per_second</td><td>▁▇▇█▇█▇▇▇▇▇</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.98448</td></tr><tr><td>eval/f1</td><td>0.82087</td></tr><tr><td>eval/loss</td><td>0.11034</td></tr><tr><td>eval/precision</td><td>0.81219</td></tr><tr><td>eval/recall</td><td>0.82973</td></tr><tr><td>eval/runtime</td><td>2.6809</td></tr><tr><td>eval/samples_per_second</td><td>344.666</td></tr><tr><td>eval/steps_per_second</td><td>21.635</td></tr><tr><td>test/accuracy</td><td>0.98448</td></tr><tr><td>test/f1</td><td>0.82087</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ModernBERT-base</strong> at: <a href='https://wandb.ai/250502_ohto_research/NCBI-disease/runs/luruvex3' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease/runs/luruvex3</a><br> View project at: <a href='https://wandb.ai/250502_ohto_research/NCBI-disease' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251129_131600-luruvex3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/1-project/1-nlp/github/nlp-util/benchmark_test/notebook/wandb/run-20251129_132158-g5hx76e9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/250502_ohto_research/NCBI-disease/runs/g5hx76e9' target=\"_blank\">Clinical_ModernBERT</a></strong> to <a href='https://wandb.ai/250502_ohto_research/NCBI-disease' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/250502_ohto_research/NCBI-disease' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/250502_ohto_research/NCBI-disease/runs/g5hx76e9' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease/runs/g5hx76e9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_843539/3916018160.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3400' max='3400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3400/3400 04:45, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.059755</td>\n",
       "      <td>0.728710</td>\n",
       "      <td>0.761118</td>\n",
       "      <td>0.744562</td>\n",
       "      <td>0.980141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.081200</td>\n",
       "      <td>0.060427</td>\n",
       "      <td>0.744431</td>\n",
       "      <td>0.806861</td>\n",
       "      <td>0.774390</td>\n",
       "      <td>0.983145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.076074</td>\n",
       "      <td>0.747771</td>\n",
       "      <td>0.745870</td>\n",
       "      <td>0.746819</td>\n",
       "      <td>0.981852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.075656</td>\n",
       "      <td>0.750853</td>\n",
       "      <td>0.838628</td>\n",
       "      <td>0.792317</td>\n",
       "      <td>0.983228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.094240</td>\n",
       "      <td>0.760922</td>\n",
       "      <td>0.796696</td>\n",
       "      <td>0.778399</td>\n",
       "      <td>0.982978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.089287</td>\n",
       "      <td>0.751163</td>\n",
       "      <td>0.820839</td>\n",
       "      <td>0.784457</td>\n",
       "      <td>0.983061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.095874</td>\n",
       "      <td>0.776442</td>\n",
       "      <td>0.820839</td>\n",
       "      <td>0.798023</td>\n",
       "      <td>0.983687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.097284</td>\n",
       "      <td>0.779499</td>\n",
       "      <td>0.831004</td>\n",
       "      <td>0.804428</td>\n",
       "      <td>0.983687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.100043</td>\n",
       "      <td>0.780576</td>\n",
       "      <td>0.827192</td>\n",
       "      <td>0.803208</td>\n",
       "      <td>0.983646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.100939</td>\n",
       "      <td>0.778846</td>\n",
       "      <td>0.823380</td>\n",
       "      <td>0.800494</td>\n",
       "      <td>0.983604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model: thomas-sounack/BioClinical-ModernBERT-base  Training ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at thomas-sounack/BioClinical-ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 5433/5433 [00:00<00:00, 7519.67 examples/s]\n",
      "Map: 100%|██████████| 924/924 [00:00<00:00, 10564.22 examples/s]\n",
      "Map: 100%|██████████| 941/941 [00:00<00:00, 2543.63 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇▄▇▇▇█████</td></tr><tr><td>eval/f1</td><td>▁▄▁▇▅▆▇████</td></tr><tr><td>eval/loss</td><td>▁▁▄▄▇▆▇▇███</td></tr><tr><td>eval/precision</td><td>▁▃▄▄▅▄▇████</td></tr><tr><td>eval/recall</td><td>▂▆▁█▅▇▇▇▇▇▇</td></tr><tr><td>eval/runtime</td><td>▃▅▅▁▃▅▂▄▅█▄</td></tr><tr><td>eval/samples_per_second</td><td>▆▄▄█▆▄▇▅▄▁▅</td></tr><tr><td>eval/steps_per_second</td><td>▆▄▄█▆▄▇▅▄▁▅</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.9836</td></tr><tr><td>eval/f1</td><td>0.80049</td></tr><tr><td>eval/loss</td><td>0.10094</td></tr><tr><td>eval/precision</td><td>0.77885</td></tr><tr><td>eval/recall</td><td>0.82338</td></tr><tr><td>eval/runtime</td><td>2.3893</td></tr><tr><td>eval/samples_per_second</td><td>386.731</td></tr><tr><td>eval/steps_per_second</td><td>24.275</td></tr><tr><td>test/accuracy</td><td>0.9836</td></tr><tr><td>test/f1</td><td>0.80049</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Clinical_ModernBERT</strong> at: <a href='https://wandb.ai/250502_ohto_research/NCBI-disease/runs/g5hx76e9' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease/runs/g5hx76e9</a><br> View project at: <a href='https://wandb.ai/250502_ohto_research/NCBI-disease' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251129_132158-g5hx76e9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/1-project/1-nlp/github/nlp-util/benchmark_test/notebook/wandb/run-20251129_132705-549zi93p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/250502_ohto_research/NCBI-disease/runs/549zi93p' target=\"_blank\">BioClinical-ModernBERT-base</a></strong> to <a href='https://wandb.ai/250502_ohto_research/NCBI-disease' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/250502_ohto_research/NCBI-disease' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/250502_ohto_research/NCBI-disease/runs/549zi93p' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease/runs/549zi93p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_843539/3916018160.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3400' max='3400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3400/3400 05:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.054914</td>\n",
       "      <td>0.736397</td>\n",
       "      <td>0.773825</td>\n",
       "      <td>0.754647</td>\n",
       "      <td>0.981476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.050489</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.809403</td>\n",
       "      <td>0.793275</td>\n",
       "      <td>0.983312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>0.055113</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.818297</td>\n",
       "      <td>0.812618</td>\n",
       "      <td>0.984605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>0.068060</td>\n",
       "      <td>0.823745</td>\n",
       "      <td>0.855146</td>\n",
       "      <td>0.839152</td>\n",
       "      <td>0.985815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.089371</td>\n",
       "      <td>0.788666</td>\n",
       "      <td>0.848793</td>\n",
       "      <td>0.817625</td>\n",
       "      <td>0.984647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.089996</td>\n",
       "      <td>0.821208</td>\n",
       "      <td>0.846252</td>\n",
       "      <td>0.833542</td>\n",
       "      <td>0.985481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.094864</td>\n",
       "      <td>0.818841</td>\n",
       "      <td>0.861499</td>\n",
       "      <td>0.839628</td>\n",
       "      <td>0.985523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.098919</td>\n",
       "      <td>0.827086</td>\n",
       "      <td>0.869123</td>\n",
       "      <td>0.847584</td>\n",
       "      <td>0.985898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.100658</td>\n",
       "      <td>0.820913</td>\n",
       "      <td>0.867853</td>\n",
       "      <td>0.843731</td>\n",
       "      <td>0.985898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.101472</td>\n",
       "      <td>0.822892</td>\n",
       "      <td>0.867853</td>\n",
       "      <td>0.844774</td>\n",
       "      <td>0.985857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, name in enumerate(models):\n",
    "    print(\"=== Model:\", name, \" Training ===\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "    tokenizer.pad_token = \"[PAD]\" \n",
    "\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "    name,\n",
    "    num_labels=len(label_names),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    )\n",
    "    \n",
    "    tokenized_datasets = dataset.map(\n",
    "        lambda x: tokenize_and_align_labels(x, tokenizer),\n",
    "        batched=True\n",
    "    )\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "    model_name = name.split(\"/\")[-1]\n",
    "    \n",
    "    wandb.init(\n",
    "    entity=\"250502_ohto_research\",\n",
    "    project=\"NCBI-disease\", name=model_name, \n",
    "    config={\n",
    "        \"model_name\": model_name,\n",
    "        \"learning_rate\": 2e-5,\n",
    "        \"batch_size\": 16,\n",
    "        \"num_epochs\": 10,\n",
    "        \"dataset\": \"NCBI-Disease\",\n",
    "    })\n",
    "\n",
    "    os.makedirs(f\"../result/ncbi/{model_name}\", exist_ok=True)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"../result/ncbi/{model_name}\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=10,\n",
    "        save_strategy=\"no\",\n",
    "        load_best_model_at_end=False,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        report_to=\"wandb\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    trainer.save_metrics(\"all\", metrics)\n",
    "\n",
    "    df_final_results = result_output_general(\n",
    "        trainer=trainer,\n",
    "        tokenized_datasets=tokenized_datasets,\n",
    "        tokenizer=tokenizer,\n",
    "        id2label=id2label,\n",
    "        num_samples_to_process=len(tokenized_datasets[\"validation\"]),\n",
    "        output_filename=f'../result/ncbi/{model_name}/results.csv'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a718e85d",
   "metadata": {},
   "source": [
    "# BC5CDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf635c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 4561/4561 [00:00<00:00, 136104.87 examples/s]\n",
      "Generating validation split: 100%|██████████| 4582/4582 [00:00<00:00, 147095.34 examples/s]\n",
      "Generating test split: 100%|██████████| 4798/4798 [00:00<00:00, 57601.76 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label names: ['O', 'B-DISEASE', 'I-DISEASE', 'B-CHEMICAL', 'I-CHEMICAL']\n",
      "ID to Label mapping: {0: 'O', 1: 'B-DISEASE', 2: 'I-DISEASE', 3: 'B-CHEMICAL', 4: 'I-CHEMICAL'}\n",
      "Label to ID mapping: {'O': 0, 'B-DISEASE': 1, 'I-DISEASE': 2, 'B-CHEMICAL': 3, 'I-CHEMICAL': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"omniquad/BC5CDR-IOB\")\n",
    "\n",
    "label_names = [\n",
    "    \"O\", \"B-DISEASE\", \"I-DISEASE\", \"B-CHEMICAL\", \"I-CHEMICAL\"\n",
    "]\n",
    "\n",
    "id2label = {i: name for i, name in enumerate(label_names)}\n",
    "label2id = {name: i for i, name in enumerate(label_names)}\n",
    "\n",
    "print(\"Label names:\", label_names)\n",
    "print(\"ID to Label mapping:\", id2label)\n",
    "print(\"Label to ID mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23846b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 4561/4561 [00:00<00:00, 21273.67 examples/s]\n",
      "Map: 100%|██████████| 4582/4582 [00:00<00:00, 39388.46 examples/s]\n",
      "Map: 100%|██████████| 4798/4798 [00:00<00:00, 35685.00 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def convert_labels_to_ids(example):\n",
    "    example['ner_tags'] = [label2id[label_str] for label_str in example['ner_tags']]\n",
    "    return example\n",
    "dataset = dataset.map(convert_labels_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dde3cc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model: microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext  Training ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 4561/4561 [00:00<00:00, 8906.09 examples/s]\n",
      "Map: 100%|██████████| 4582/4582 [00:00<00:00, 9494.54 examples/s]\n",
      "Map: 100%|██████████| 4798/4798 [00:00<00:00, 9819.01 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▄▆█▆▇▇████</td></tr><tr><td>eval/f1</td><td>▁▄▅▇▆▇▇████</td></tr><tr><td>eval/loss</td><td>▂▁▂▃▆▆▇████</td></tr><tr><td>eval/precision</td><td>▁▄▆█▅█▇████</td></tr><tr><td>eval/recall</td><td>▁▄▄▇▇▆▇████</td></tr><tr><td>eval/runtime</td><td>▃▄▁█▄▂▃▄▁▂▄</td></tr><tr><td>eval/samples_per_second</td><td>▆▅█▁▅▇▆▅█▆▄</td></tr><tr><td>eval/steps_per_second</td><td>▆▅█▁▅▇▆▅█▆▄</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.98586</td></tr><tr><td>eval/f1</td><td>0.84477</td></tr><tr><td>eval/loss</td><td>0.10147</td></tr><tr><td>eval/precision</td><td>0.82289</td></tr><tr><td>eval/recall</td><td>0.86785</td></tr><tr><td>eval/runtime</td><td>2.7104</td></tr><tr><td>eval/samples_per_second</td><td>340.912</td></tr><tr><td>eval/steps_per_second</td><td>21.399</td></tr><tr><td>test/accuracy</td><td>0.98586</td></tr><tr><td>test/f1</td><td>0.84477</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">BioClinical-ModernBERT-base</strong> at: <a href='https://wandb.ai/250502_ohto_research/NCBI-disease/runs/549zi93p' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease/runs/549zi93p</a><br> View project at: <a href='https://wandb.ai/250502_ohto_research/NCBI-disease' target=\"_blank\">https://wandb.ai/250502_ohto_research/NCBI-disease</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251129_132705-549zi93p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/1-project/1-nlp/github/nlp-util/benchmark_test/notebook/wandb/run-20251129_133256-7g84gmps</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/250502_ohto_research/BC5/runs/7g84gmps' target=\"_blank\">BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext</a></strong> to <a href='https://wandb.ai/250502_ohto_research/BC5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/250502_ohto_research/BC5' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/250502_ohto_research/BC5/runs/7g84gmps' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5/runs/7g84gmps</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_843539/1228510784.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2860' max='2860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2860/2860 03:54, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.082857</td>\n",
       "      <td>0.847195</td>\n",
       "      <td>0.894089</td>\n",
       "      <td>0.870011</td>\n",
       "      <td>0.972678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.121300</td>\n",
       "      <td>0.076229</td>\n",
       "      <td>0.876698</td>\n",
       "      <td>0.901282</td>\n",
       "      <td>0.888820</td>\n",
       "      <td>0.977804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.121300</td>\n",
       "      <td>0.086503</td>\n",
       "      <td>0.878622</td>\n",
       "      <td>0.903992</td>\n",
       "      <td>0.891127</td>\n",
       "      <td>0.976365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.096066</td>\n",
       "      <td>0.895124</td>\n",
       "      <td>0.912853</td>\n",
       "      <td>0.903902</td>\n",
       "      <td>0.979098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.111860</td>\n",
       "      <td>0.863264</td>\n",
       "      <td>0.922026</td>\n",
       "      <td>0.891678</td>\n",
       "      <td>0.975190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.114379</td>\n",
       "      <td>0.888190</td>\n",
       "      <td>0.912540</td>\n",
       "      <td>0.900201</td>\n",
       "      <td>0.977923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.121600</td>\n",
       "      <td>0.893972</td>\n",
       "      <td>0.910560</td>\n",
       "      <td>0.902190</td>\n",
       "      <td>0.978144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.128511</td>\n",
       "      <td>0.892719</td>\n",
       "      <td>0.912540</td>\n",
       "      <td>0.902521</td>\n",
       "      <td>0.978630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.129583</td>\n",
       "      <td>0.895001</td>\n",
       "      <td>0.912540</td>\n",
       "      <td>0.903685</td>\n",
       "      <td>0.978766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.130246</td>\n",
       "      <td>0.895716</td>\n",
       "      <td>0.913270</td>\n",
       "      <td>0.904408</td>\n",
       "      <td>0.978970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model: dmis-lab/biobert-v1.1  Training ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dmis-lab/biobert-v1.1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 4561/4561 [00:00<00:00, 9359.83 examples/s]\n",
      "Map: 100%|██████████| 4582/4582 [00:00<00:00, 10056.76 examples/s]\n",
      "Map: 100%|██████████| 4798/4798 [00:00<00:00, 8332.75 examples/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇▅█▄▇▇▇███</td></tr><tr><td>eval/f1</td><td>▁▅▅█▅▇█████</td></tr><tr><td>eval/loss</td><td>▂▁▂▄▆▆▇████</td></tr><tr><td>eval/precision</td><td>▁▅▆█▃▇█████</td></tr><tr><td>eval/recall</td><td>▁▃▃▆█▆▅▆▆▆▆</td></tr><tr><td>eval/runtime</td><td>▃▂█▃▂▃▁▂▁▃▁</td></tr><tr><td>eval/samples_per_second</td><td>▆▇▁▆▇▆█▇█▆█</td></tr><tr><td>eval/steps_per_second</td><td>▆▇▁▆▇▆█▇█▆█</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.97897</td></tr><tr><td>eval/f1</td><td>0.90441</td></tr><tr><td>eval/loss</td><td>0.13025</td></tr><tr><td>eval/precision</td><td>0.89572</td></tr><tr><td>eval/recall</td><td>0.91327</td></tr><tr><td>eval/runtime</td><td>6.5051</td></tr><tr><td>eval/samples_per_second</td><td>704.372</td></tr><tr><td>eval/steps_per_second</td><td>44.119</td></tr><tr><td>test/accuracy</td><td>0.97897</td></tr><tr><td>test/f1</td><td>0.90441</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext</strong> at: <a href='https://wandb.ai/250502_ohto_research/BC5/runs/7g84gmps' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5/runs/7g84gmps</a><br> View project at: <a href='https://wandb.ai/250502_ohto_research/BC5' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251129_133256-7g84gmps/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/1-project/1-nlp/github/nlp-util/benchmark_test/notebook/wandb/run-20251129_133713-a9vqksn6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/250502_ohto_research/BC5/runs/a9vqksn6' target=\"_blank\">biobert-v1.1</a></strong> to <a href='https://wandb.ai/250502_ohto_research/BC5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/250502_ohto_research/BC5' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/250502_ohto_research/BC5/runs/a9vqksn6' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5/runs/a9vqksn6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_843539/1228510784.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2860' max='2860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2860/2860 04:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.077478</td>\n",
       "      <td>0.853661</td>\n",
       "      <td>0.894600</td>\n",
       "      <td>0.873651</td>\n",
       "      <td>0.973872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.110500</td>\n",
       "      <td>0.079682</td>\n",
       "      <td>0.867188</td>\n",
       "      <td>0.901272</td>\n",
       "      <td>0.883902</td>\n",
       "      <td>0.975984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.110500</td>\n",
       "      <td>0.094465</td>\n",
       "      <td>0.856060</td>\n",
       "      <td>0.906485</td>\n",
       "      <td>0.880551</td>\n",
       "      <td>0.973285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.099452</td>\n",
       "      <td>0.888456</td>\n",
       "      <td>0.902627</td>\n",
       "      <td>0.895485</td>\n",
       "      <td>0.977313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.118190</td>\n",
       "      <td>0.860665</td>\n",
       "      <td>0.909925</td>\n",
       "      <td>0.884610</td>\n",
       "      <td>0.974835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.120439</td>\n",
       "      <td>0.886769</td>\n",
       "      <td>0.901376</td>\n",
       "      <td>0.894013</td>\n",
       "      <td>0.977466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.127201</td>\n",
       "      <td>0.887654</td>\n",
       "      <td>0.899500</td>\n",
       "      <td>0.893538</td>\n",
       "      <td>0.976904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.137474</td>\n",
       "      <td>0.879281</td>\n",
       "      <td>0.907423</td>\n",
       "      <td>0.893130</td>\n",
       "      <td>0.976683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.138912</td>\n",
       "      <td>0.877722</td>\n",
       "      <td>0.907736</td>\n",
       "      <td>0.892476</td>\n",
       "      <td>0.976640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.139211</td>\n",
       "      <td>0.883690</td>\n",
       "      <td>0.903774</td>\n",
       "      <td>0.893619</td>\n",
       "      <td>0.976921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model: google-bert/bert-base-cased  Training ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 4561/4561 [00:00<00:00, 10349.76 examples/s]\n",
      "Map: 100%|██████████| 4582/4582 [00:00<00:00, 10691.87 examples/s]\n",
      "Map: 100%|██████████| 4798/4798 [00:00<00:00, 8286.66 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▂▆▁█▄█▇▇▇▇▇</td></tr><tr><td>eval/f1</td><td>▁▄▃█▅█▇▇▇▇▇</td></tr><tr><td>eval/loss</td><td>▁▁▃▃▆▆▇████</td></tr><tr><td>eval/precision</td><td>▁▄▁█▂██▆▆▇▇</td></tr><tr><td>eval/recall</td><td>▁▄▆▅█▄▃▇▇▅▅</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁▄█▃▂▁▄</td></tr><tr><td>eval/samples_per_second</td><td>█████▄▁▆▇█▄</td></tr><tr><td>eval/steps_per_second</td><td>█████▄▁▆▇█▄</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.97692</td></tr><tr><td>eval/f1</td><td>0.89362</td></tr><tr><td>eval/loss</td><td>0.13921</td></tr><tr><td>eval/precision</td><td>0.88369</td></tr><tr><td>eval/recall</td><td>0.90377</td></tr><tr><td>eval/runtime</td><td>8.5503</td></tr><tr><td>eval/samples_per_second</td><td>535.885</td></tr><tr><td>eval/steps_per_second</td><td>33.566</td></tr><tr><td>test/accuracy</td><td>0.97692</td></tr><tr><td>test/f1</td><td>0.89362</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">biobert-v1.1</strong> at: <a href='https://wandb.ai/250502_ohto_research/BC5/runs/a9vqksn6' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5/runs/a9vqksn6</a><br> View project at: <a href='https://wandb.ai/250502_ohto_research/BC5' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251129_133713-a9vqksn6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/1-project/1-nlp/github/nlp-util/benchmark_test/notebook/wandb/run-20251129_134217-ek4ls09x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/250502_ohto_research/BC5/runs/ek4ls09x' target=\"_blank\">bert-base-cased</a></strong> to <a href='https://wandb.ai/250502_ohto_research/BC5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/250502_ohto_research/BC5' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/250502_ohto_research/BC5/runs/ek4ls09x' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5/runs/ek4ls09x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_843539/1228510784.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2860' max='2860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2860/2860 04:32, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.104940</td>\n",
       "      <td>0.786476</td>\n",
       "      <td>0.860926</td>\n",
       "      <td>0.822019</td>\n",
       "      <td>0.964240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.122100</td>\n",
       "      <td>0.096893</td>\n",
       "      <td>0.812664</td>\n",
       "      <td>0.873749</td>\n",
       "      <td>0.842100</td>\n",
       "      <td>0.969265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.122100</td>\n",
       "      <td>0.118940</td>\n",
       "      <td>0.831228</td>\n",
       "      <td>0.871351</td>\n",
       "      <td>0.850817</td>\n",
       "      <td>0.969035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.138401</td>\n",
       "      <td>0.845289</td>\n",
       "      <td>0.862385</td>\n",
       "      <td>0.853752</td>\n",
       "      <td>0.970193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.151445</td>\n",
       "      <td>0.827254</td>\n",
       "      <td>0.877189</td>\n",
       "      <td>0.851490</td>\n",
       "      <td>0.968822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>0.161690</td>\n",
       "      <td>0.839175</td>\n",
       "      <td>0.873645</td>\n",
       "      <td>0.856063</td>\n",
       "      <td>0.970329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.173251</td>\n",
       "      <td>0.840971</td>\n",
       "      <td>0.870517</td>\n",
       "      <td>0.855489</td>\n",
       "      <td>0.970449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.186626</td>\n",
       "      <td>0.843393</td>\n",
       "      <td>0.869683</td>\n",
       "      <td>0.856336</td>\n",
       "      <td>0.970108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.186363</td>\n",
       "      <td>0.847978</td>\n",
       "      <td>0.872289</td>\n",
       "      <td>0.859962</td>\n",
       "      <td>0.971147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.188997</td>\n",
       "      <td>0.846278</td>\n",
       "      <td>0.873540</td>\n",
       "      <td>0.859693</td>\n",
       "      <td>0.970892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model: answerdotai/ModernBERT-base  Training ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 4561/4561 [00:00<00:00, 9193.50 examples/s]\n",
      "Map: 100%|██████████| 4582/4582 [00:00<00:00, 10792.53 examples/s]\n",
      "Map: 100%|██████████| 4798/4798 [00:00<00:00, 8363.44 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▆▇▆▇▇▇███</td></tr><tr><td>eval/f1</td><td>▁▅▆▇▆▇▇▇███</td></tr><tr><td>eval/loss</td><td>▂▁▃▄▅▆▇████</td></tr><tr><td>eval/precision</td><td>▁▄▆█▆▇▇▇███</td></tr><tr><td>eval/recall</td><td>▁▇▅▂█▆▅▅▆▆▆</td></tr><tr><td>eval/runtime</td><td>▆▄▇▆▆▆▃▃▃█▁</td></tr><tr><td>eval/samples_per_second</td><td>▃▅▂▃▃▃▆▆▅▁█</td></tr><tr><td>eval/steps_per_second</td><td>▃▅▂▃▃▃▆▆▅▁█</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.97089</td></tr><tr><td>eval/f1</td><td>0.85969</td></tr><tr><td>eval/loss</td><td>0.189</td></tr><tr><td>eval/precision</td><td>0.84628</td></tr><tr><td>eval/recall</td><td>0.87354</td></tr><tr><td>eval/runtime</td><td>7.5011</td></tr><tr><td>eval/samples_per_second</td><td>610.844</td></tr><tr><td>eval/steps_per_second</td><td>38.261</td></tr><tr><td>test/accuracy</td><td>0.97089</td></tr><tr><td>test/f1</td><td>0.85969</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bert-base-cased</strong> at: <a href='https://wandb.ai/250502_ohto_research/BC5/runs/ek4ls09x' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5/runs/ek4ls09x</a><br> View project at: <a href='https://wandb.ai/250502_ohto_research/BC5' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251129_134217-ek4ls09x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/1-project/1-nlp/github/nlp-util/benchmark_test/notebook/wandb/run-20251129_134714-p5fgr9cv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/250502_ohto_research/BC5/runs/p5fgr9cv' target=\"_blank\">ModernBERT-base</a></strong> to <a href='https://wandb.ai/250502_ohto_research/BC5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/250502_ohto_research/BC5' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/250502_ohto_research/BC5/runs/p5fgr9cv' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5/runs/p5fgr9cv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_843539/1228510784.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2860' max='2860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2860/2860 06:49, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.110805</td>\n",
       "      <td>0.760685</td>\n",
       "      <td>0.842456</td>\n",
       "      <td>0.799485</td>\n",
       "      <td>0.962311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.127500</td>\n",
       "      <td>0.128122</td>\n",
       "      <td>0.843789</td>\n",
       "      <td>0.781149</td>\n",
       "      <td>0.811262</td>\n",
       "      <td>0.964048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.127500</td>\n",
       "      <td>0.128068</td>\n",
       "      <td>0.811516</td>\n",
       "      <td>0.843499</td>\n",
       "      <td>0.827198</td>\n",
       "      <td>0.965156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.171176</td>\n",
       "      <td>0.858732</td>\n",
       "      <td>0.820769</td>\n",
       "      <td>0.839322</td>\n",
       "      <td>0.967617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.167335</td>\n",
       "      <td>0.831738</td>\n",
       "      <td>0.842665</td>\n",
       "      <td>0.837166</td>\n",
       "      <td>0.967992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.197796</td>\n",
       "      <td>0.852325</td>\n",
       "      <td>0.835262</td>\n",
       "      <td>0.843707</td>\n",
       "      <td>0.968597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.205672</td>\n",
       "      <td>0.840449</td>\n",
       "      <td>0.843603</td>\n",
       "      <td>0.842023</td>\n",
       "      <td>0.968639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.215210</td>\n",
       "      <td>0.843070</td>\n",
       "      <td>0.839641</td>\n",
       "      <td>0.841352</td>\n",
       "      <td>0.967847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.213651</td>\n",
       "      <td>0.839149</td>\n",
       "      <td>0.847461</td>\n",
       "      <td>0.843285</td>\n",
       "      <td>0.968597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.217070</td>\n",
       "      <td>0.842423</td>\n",
       "      <td>0.843916</td>\n",
       "      <td>0.843169</td>\n",
       "      <td>0.968563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model: Simonlee711/Clinical_ModernBERT  Training ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at Simonlee711/Clinical_ModernBERT and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 4561/4561 [00:00<00:00, 10160.37 examples/s]\n",
      "Map: 100%|██████████| 4582/4582 [00:00<00:00, 10529.83 examples/s]\n",
      "Map: 100%|██████████| 4798/4798 [00:00<00:00, 5538.03 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▃▄▇▇██▇███</td></tr><tr><td>eval/f1</td><td>▁▃▅▇▇██████</td></tr><tr><td>eval/loss</td><td>▁▂▂▅▅▇▇████</td></tr><tr><td>eval/precision</td><td>▁▇▅█▆█▇▇▇▇▇</td></tr><tr><td>eval/recall</td><td>▇▁█▅▇▇█▇███</td></tr><tr><td>eval/runtime</td><td>▁▂█▂▂▄▂▃▃▂▂</td></tr><tr><td>eval/samples_per_second</td><td>█▇▁▇▇▅▇▆▆▇▇</td></tr><tr><td>eval/steps_per_second</td><td>█▇▁▇▇▅▇▆▆▇▇</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.96856</td></tr><tr><td>eval/f1</td><td>0.84317</td></tr><tr><td>eval/loss</td><td>0.21707</td></tr><tr><td>eval/precision</td><td>0.84242</td></tr><tr><td>eval/recall</td><td>0.84392</td></tr><tr><td>eval/runtime</td><td>11.7616</td></tr><tr><td>eval/samples_per_second</td><td>389.571</td></tr><tr><td>eval/steps_per_second</td><td>24.401</td></tr><tr><td>test/accuracy</td><td>0.96856</td></tr><tr><td>test/f1</td><td>0.84317</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ModernBERT-base</strong> at: <a href='https://wandb.ai/250502_ohto_research/BC5/runs/p5fgr9cv' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5/runs/p5fgr9cv</a><br> View project at: <a href='https://wandb.ai/250502_ohto_research/BC5' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251129_134714-p5fgr9cv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/1-project/1-nlp/github/nlp-util/benchmark_test/notebook/wandb/run-20251129_135437-665gk2nh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/250502_ohto_research/BC5/runs/665gk2nh' target=\"_blank\">Clinical_ModernBERT</a></strong> to <a href='https://wandb.ai/250502_ohto_research/BC5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/250502_ohto_research/BC5' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/250502_ohto_research/BC5/runs/665gk2nh' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5/runs/665gk2nh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_843539/1228510784.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2860' max='2860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2860/2860 05:24, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.121918</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.776561</td>\n",
       "      <td>0.786069</td>\n",
       "      <td>0.960531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>0.131500</td>\n",
       "      <td>0.809702</td>\n",
       "      <td>0.788343</td>\n",
       "      <td>0.798880</td>\n",
       "      <td>0.962532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>0.146457</td>\n",
       "      <td>0.813245</td>\n",
       "      <td>0.804087</td>\n",
       "      <td>0.808640</td>\n",
       "      <td>0.963001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.172387</td>\n",
       "      <td>0.809048</td>\n",
       "      <td>0.811073</td>\n",
       "      <td>0.810059</td>\n",
       "      <td>0.963614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.182775</td>\n",
       "      <td>0.810892</td>\n",
       "      <td>0.818163</td>\n",
       "      <td>0.814511</td>\n",
       "      <td>0.964670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.189245</td>\n",
       "      <td>0.806652</td>\n",
       "      <td>0.824314</td>\n",
       "      <td>0.815388</td>\n",
       "      <td>0.964347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.209020</td>\n",
       "      <td>0.801517</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.813617</td>\n",
       "      <td>0.964568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.214871</td>\n",
       "      <td>0.802693</td>\n",
       "      <td>0.826713</td>\n",
       "      <td>0.814526</td>\n",
       "      <td>0.964415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.224123</td>\n",
       "      <td>0.814765</td>\n",
       "      <td>0.815869</td>\n",
       "      <td>0.815316</td>\n",
       "      <td>0.964696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.225102</td>\n",
       "      <td>0.812163</td>\n",
       "      <td>0.817329</td>\n",
       "      <td>0.814738</td>\n",
       "      <td>0.964594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model: thomas-sounack/BioClinical-ModernBERT-base  Training ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForTokenClassification were not initialized from the model checkpoint at thomas-sounack/BioClinical-ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 4561/4561 [00:00<00:00, 8558.19 examples/s]\n",
      "Map: 100%|██████████| 4582/4582 [00:00<00:00, 10309.45 examples/s]\n",
      "Map: 100%|██████████| 4798/4798 [00:00<00:00, 8699.81 examples/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▄▅▆█▇█████</td></tr><tr><td>eval/f1</td><td>▁▄▆▇███████</td></tr><tr><td>eval/loss</td><td>▁▂▃▄▅▆▇▇███</td></tr><tr><td>eval/precision</td><td>▁▆▇▆▇▅▃▄█▇▇</td></tr><tr><td>eval/recall</td><td>▁▃▅▆▇███▆▇▇</td></tr><tr><td>eval/runtime</td><td>▁▄▂▆▂▁█▄▃▅▁</td></tr><tr><td>eval/samples_per_second</td><td>█▅▇▃▇█▁▅▆▄█</td></tr><tr><td>eval/steps_per_second</td><td>█▅▇▃▇█▁▅▆▄█</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>+11</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.96459</td></tr><tr><td>eval/f1</td><td>0.81474</td></tr><tr><td>eval/loss</td><td>0.2251</td></tr><tr><td>eval/precision</td><td>0.81216</td></tr><tr><td>eval/recall</td><td>0.81733</td></tr><tr><td>eval/runtime</td><td>8.4817</td></tr><tr><td>eval/samples_per_second</td><td>540.222</td></tr><tr><td>eval/steps_per_second</td><td>33.838</td></tr><tr><td>test/accuracy</td><td>0.96459</td></tr><tr><td>test/f1</td><td>0.81474</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Clinical_ModernBERT</strong> at: <a href='https://wandb.ai/250502_ohto_research/BC5/runs/665gk2nh' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5/runs/665gk2nh</a><br> View project at: <a href='https://wandb.ai/250502_ohto_research/BC5' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251129_135437-665gk2nh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/1-project/1-nlp/github/nlp-util/benchmark_test/notebook/wandb/run-20251129_140028-0pkgcbwe</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/250502_ohto_research/BC5/runs/0pkgcbwe' target=\"_blank\">BioClinical-ModernBERT-base</a></strong> to <a href='https://wandb.ai/250502_ohto_research/BC5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/250502_ohto_research/BC5' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/250502_ohto_research/BC5/runs/0pkgcbwe' target=\"_blank\">https://wandb.ai/250502_ohto_research/BC5/runs/0pkgcbwe</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_843539/1228510784.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2860' max='2860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2860/2860 06:44, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.092396</td>\n",
       "      <td>0.813974</td>\n",
       "      <td>0.878219</td>\n",
       "      <td>0.844877</td>\n",
       "      <td>0.968529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.101800</td>\n",
       "      <td>0.105089</td>\n",
       "      <td>0.859606</td>\n",
       "      <td>0.810760</td>\n",
       "      <td>0.834469</td>\n",
       "      <td>0.969397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.101800</td>\n",
       "      <td>0.112331</td>\n",
       "      <td>0.841091</td>\n",
       "      <td>0.864769</td>\n",
       "      <td>0.852766</td>\n",
       "      <td>0.971918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.135920</td>\n",
       "      <td>0.859498</td>\n",
       "      <td>0.875091</td>\n",
       "      <td>0.867225</td>\n",
       "      <td>0.973835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.151826</td>\n",
       "      <td>0.855923</td>\n",
       "      <td>0.877698</td>\n",
       "      <td>0.866674</td>\n",
       "      <td>0.973562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.169289</td>\n",
       "      <td>0.868666</td>\n",
       "      <td>0.866854</td>\n",
       "      <td>0.867759</td>\n",
       "      <td>0.973971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.165084</td>\n",
       "      <td>0.852307</td>\n",
       "      <td>0.882077</td>\n",
       "      <td>0.866937</td>\n",
       "      <td>0.973920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.174699</td>\n",
       "      <td>0.862749</td>\n",
       "      <td>0.875613</td>\n",
       "      <td>0.869133</td>\n",
       "      <td>0.974065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.178495</td>\n",
       "      <td>0.861598</td>\n",
       "      <td>0.875613</td>\n",
       "      <td>0.868549</td>\n",
       "      <td>0.973980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.179900</td>\n",
       "      <td>0.861850</td>\n",
       "      <td>0.875508</td>\n",
       "      <td>0.868625</td>\n",
       "      <td>0.974014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, name in enumerate(models):\n",
    "    print(\"=== Model:\", name, \" Training ===\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "    tokenizer.pad_token = \"[PAD]\" \n",
    "\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "    name,\n",
    "    num_labels=len(label_names),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    )\n",
    "    \n",
    "    tokenized_datasets = dataset.map(\n",
    "        lambda x: tokenize_and_align_labels(x, tokenizer),\n",
    "        batched=True\n",
    "    )\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "    model_name = name.split(\"/\")[-1]\n",
    "    \n",
    "    wandb.init(\n",
    "    entity=\"250502_ohto_research\",\n",
    "    project=\"BC5\", name=model_name, \n",
    "    config={\n",
    "        \"model_name\": model_name,\n",
    "        \"learning_rate\": 2e-5,\n",
    "        \"batch_size\": 16,\n",
    "        \"num_epochs\": 10,\n",
    "        \"dataset\": \"BC5\",\n",
    "    })\n",
    "\n",
    "    os.makedirs(f\"../result/bc5/{model_name}\", exist_ok=True)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"../result/bc5/{model_name}\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=10,\n",
    "        save_strategy=\"no\",\n",
    "        load_best_model_at_end=False,\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy=\"epoch\",\n",
    "        report_to=\"wandb\",\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate()\n",
    "    trainer.save_metrics(\"all\", metrics)\n",
    "\n",
    "    df_final_results = result_output_general(\n",
    "        trainer=trainer,\n",
    "        tokenized_datasets=tokenized_datasets,\n",
    "        tokenizer=tokenizer,\n",
    "        id2label=id2label,\n",
    "        num_samples_to_process=len(tokenized_datasets[\"validation\"]),\n",
    "        output_filename=f'../result/bc5/{model_name}/results.csv'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce1ea53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
